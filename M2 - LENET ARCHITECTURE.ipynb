{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LENET ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 10:18:23.943838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730177303.956197   17562 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730177303.959664   17562 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 10:18:23.972996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator for data augmentation and preprocessing\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your dataset directory\n",
    "dataset_dir = 'Dataset'\n",
    "\n",
    "# Set the batch size and number of classes\n",
    "batch_size = 64\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 640 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess the dataset using the ImageDataGenerator\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sandy3o/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-10-29 10:18:34.648236: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,028</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m37\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m36,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m1,179,904\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │         \u001b[38;5;34m1,028\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,218,820</span> (4.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,218,820\u001b[0m (4.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,218,820</span> (4.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,218,820\u001b[0m (4.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "MODEL=Sequential()\n",
    "MODEL.add(Convolution2D(filters=32, kernel_size=(3,3), strides=(3,3), input_shape=(224,224,3), padding=('valid'), activation='relu'))\n",
    "MODEL.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "MODEL.add(Convolution2D(filters=128, kernel_size=(3,3), strides=(3,3), padding=('valid'), activation='relu'))\n",
    "MODEL.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "MODEL.add(Flatten())\n",
    "MODEL.add(Dense(256, activation='relu'))\n",
    "MODEL.add(Dense(4, activation='softmax'))\n",
    "\n",
    "OPT    = tensorflow.keras.optimizers.Adam(0.001)\n",
    "\n",
    "MODEL.compile(optimizer=OPT,loss='categorical_crossentropy',metrics=[\"accuracy\", tensorflow.keras.metrics.Precision()])\n",
    "MODEL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'callbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLENET.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcallbacks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCheckpoint\n\u001b[1;32m      4\u001b[0m M \u001b[38;5;241m=\u001b[39m ModelCheckpoint(model_path, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'callbacks'"
     ]
    }
   ],
   "source": [
    "model_path = \"LENET.h5\"\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "M = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'M' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m history \u001b[38;5;241m=\u001b[39m MODEL\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      2\u001b[0m     train_generator,\n\u001b[1;32m      3\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator,\n\u001b[1;32m      4\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m----> 5\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[M]  \u001b[38;5;66;03m# Add the callbacks here\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'M' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.8687 - precision: 0.8770\n",
      "Epoch 72: val_accuracy did not improve from 0.90625\n",
      "10/10 [==============================] - 10s 1s/step - loss: 0.3448 - accuracy: 0.8687 - precision: 0.8770 - val_loss: 0.3399 - val_accuracy: 0.8562 - val_precision: 0.8608\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3976 - accuracy: 0.8234 - precision: 0.8363\n",
      "Epoch 73: val_accuracy did not improve from 0.90625\n",
      "10/10 [==============================] - 9s 970ms/step - loss: 0.3976 - accuracy: 0.8234 - precision: 0.8363 - val_loss: 0.5884 - val_accuracy: 0.7812 - val_precision: 0.7922\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.8109 - precision: 0.8252\n",
      "Epoch 74: val_accuracy improved from 0.90625 to 0.91875, saving model to LENET.h5\n",
      "10/10 [==============================] - 10s 1000ms/step - loss: 0.4461 - accuracy: 0.8109 - precision: 0.8252 - val_loss: 0.3076 - val_accuracy: 0.9187 - val_precision: 0.9351\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.8453 - precision: 0.8560\n",
      "Epoch 75: val_accuracy did not improve from 0.91875\n",
      "10/10 [==============================] - 9s 961ms/step - loss: 0.3842 - accuracy: 0.8453 - precision: 0.8560 - val_loss: 0.4031 - val_accuracy: 0.8375 - val_precision: 0.8471\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3615 - accuracy: 0.8687 - precision: 0.8795\n",
      "Epoch 76: val_accuracy did not improve from 0.91875\n",
      "10/10 [==============================] - 10s 975ms/step - loss: 0.3615 - accuracy: 0.8687 - precision: 0.8795 - val_loss: 0.3465 - val_accuracy: 0.8687 - val_precision: 0.8645\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3661 - accuracy: 0.8594 - precision: 0.8824\n",
      "Epoch 77: val_accuracy did not improve from 0.91875\n",
      "10/10 [==============================] - 10s 967ms/step - loss: 0.3661 - accuracy: 0.8594 - precision: 0.8824 - val_loss: 0.2340 - val_accuracy: 0.9187 - val_precision: 0.9245\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.8594 - precision: 0.8754\n",
      "Epoch 78: val_accuracy did not improve from 0.91875\n",
      "10/10 [==============================] - 9s 952ms/step - loss: 0.3498 - accuracy: 0.8594 - precision: 0.8754 - val_loss: 0.2780 - val_accuracy: 0.9000 - val_precision: 0.9226\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.8656 - precision: 0.8792\n",
      "Epoch 79: val_accuracy did not improve from 0.91875\n",
      "10/10 [==============================] - 10s 979ms/step - loss: 0.3495 - accuracy: 0.8656 - precision: 0.8792 - val_loss: 0.3483 - val_accuracy: 0.9000 - val_precision: 0.9103\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.8797 - precision: 0.8974\n",
      "Epoch 80: val_accuracy did not improve from 0.91875\n",
      "10/10 [==============================] - 9s 963ms/step - loss: 0.3377 - accuracy: 0.8797 - precision: 0.8974 - val_loss: 0.3750 - val_accuracy: 0.8687 - val_precision: 0.8903\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3300 - accuracy: 0.8656 - precision: 0.8805\n",
      "Epoch 81: val_accuracy did not improve from 0.91875\n",
      "10/10 [==============================] - 10s 982ms/step - loss: 0.3300 - accuracy: 0.8656 - precision: 0.8805 - val_loss: 0.3972 - val_accuracy: 0.8500 - val_precision: 0.8526\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.8375 - precision: 0.8476\n",
      "Epoch 82: val_accuracy did not improve from 0.91875\n",
      "10/10 [==============================] - 9s 964ms/step - loss: 0.4287 - accuracy: 0.8375 - precision: 0.8476 - val_loss: 0.3646 - val_accuracy: 0.8687 - val_precision: 0.8933\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.8578 - precision: 0.8628\n",
      "Epoch 83: val_accuracy improved from 0.91875 to 0.92500, saving model to LENET.h5\n",
      "10/10 [==============================] - 9s 953ms/step - loss: 0.3507 - accuracy: 0.8578 - precision: 0.8628 - val_loss: 0.2794 - val_accuracy: 0.9250 - val_precision: 0.9359\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.8750 - precision: 0.8889\n",
      "Epoch 84: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 981ms/step - loss: 0.3326 - accuracy: 0.8750 - precision: 0.8889 - val_loss: 0.3586 - val_accuracy: 0.8687 - val_precision: 0.8718\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3500 - accuracy: 0.8687 - precision: 0.8860\n",
      "Epoch 85: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.3500 - accuracy: 0.8687 - precision: 0.8860 - val_loss: 0.3526 - val_accuracy: 0.8875 - val_precision: 0.8917\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8813 - precision: 0.8959\n",
      "Epoch 86: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 975ms/step - loss: 0.3060 - accuracy: 0.8813 - precision: 0.8959 - val_loss: 0.3319 - val_accuracy: 0.8687 - val_precision: 0.8831\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.8625 - precision: 0.8754\n",
      "Epoch 87: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 973ms/step - loss: 0.3515 - accuracy: 0.8625 - precision: 0.8754 - val_loss: 0.3927 - val_accuracy: 0.8625 - val_precision: 0.8645\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.8875 - precision: 0.8946\n",
      "Epoch 88: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 964ms/step - loss: 0.3038 - accuracy: 0.8875 - precision: 0.8946 - val_loss: 0.3523 - val_accuracy: 0.8750 - val_precision: 0.8854\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.8844 - precision: 0.8962\n",
      "Epoch 89: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 981ms/step - loss: 0.3169 - accuracy: 0.8844 - precision: 0.8962 - val_loss: 0.3679 - val_accuracy: 0.8750 - val_precision: 0.8903\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.8750 - precision: 0.8782\n",
      "Epoch 90: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 9s 955ms/step - loss: 0.3257 - accuracy: 0.8750 - precision: 0.8782 - val_loss: 0.3658 - val_accuracy: 0.8562 - val_precision: 0.8616\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.8625 - precision: 0.8776\n",
      "Epoch 91: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 969ms/step - loss: 0.3403 - accuracy: 0.8625 - precision: 0.8776 - val_loss: 0.3241 - val_accuracy: 0.8625 - val_precision: 0.8671\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3134 - accuracy: 0.8719 - precision: 0.8844\n",
      "Epoch 92: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 9s 953ms/step - loss: 0.3134 - accuracy: 0.8719 - precision: 0.8844 - val_loss: 0.2952 - val_accuracy: 0.8938 - val_precision: 0.9139\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.8547 - precision: 0.8668\n",
      "Epoch 93: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 955ms/step - loss: 0.3388 - accuracy: 0.8547 - precision: 0.8668 - val_loss: 0.3016 - val_accuracy: 0.8813 - val_precision: 0.8854\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.8797 - precision: 0.8952\n",
      "Epoch 94: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 967ms/step - loss: 0.3064 - accuracy: 0.8797 - precision: 0.8952 - val_loss: 0.2640 - val_accuracy: 0.9187 - val_precision: 0.9236\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.8781 - precision: 0.8914\n",
      "Epoch 95: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 9s 947ms/step - loss: 0.3232 - accuracy: 0.8781 - precision: 0.8914 - val_loss: 0.3124 - val_accuracy: 0.8938 - val_precision: 0.9156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.8844 - precision: 0.8947\n",
      "Epoch 96: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 968ms/step - loss: 0.2982 - accuracy: 0.8844 - precision: 0.8947 - val_loss: 0.2862 - val_accuracy: 0.9187 - val_precision: 0.9245\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.8766 - precision: 0.8876\n",
      "Epoch 97: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 9s 954ms/step - loss: 0.3189 - accuracy: 0.8766 - precision: 0.8876 - val_loss: 0.3111 - val_accuracy: 0.9062 - val_precision: 0.9161\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.8891 - precision: 0.8965\n",
      "Epoch 98: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 955ms/step - loss: 0.2950 - accuracy: 0.8891 - precision: 0.8965 - val_loss: 0.3856 - val_accuracy: 0.8438 - val_precision: 0.8438\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3145 - accuracy: 0.8672 - precision: 0.8766\n",
      "Epoch 99: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 982ms/step - loss: 0.3145 - accuracy: 0.8672 - precision: 0.8766 - val_loss: 0.4248 - val_accuracy: 0.8188 - val_precision: 0.8291\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.8672 - precision: 0.8800\n",
      "Epoch 100: val_accuracy did not improve from 0.92500\n",
      "10/10 [==============================] - 10s 977ms/step - loss: 0.3538 - accuracy: 0.8672 - precision: 0.8800 - val_loss: 0.4752 - val_accuracy: 0.8250 - val_precision: 0.8344\n"
     ]
    }
   ],
   "source": [
    "history = MODEL.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[M]  # Add the callbacks here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m34\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "for i in range(34):\n",
    "    if i%5 == 0:\n",
    "        plt.annotate(np.round(history.history['accuracy'][i]*100,2),xy=(i,history.history['accuracy'][i]))\n",
    "\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m34\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "for i in range(34):\n",
    "    if i%5 == 0:\n",
    "        plt.annotate(np.round(history.history['loss'][i]*100,2),xy=(i,history.history['loss'][i]))\n",
    "\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
